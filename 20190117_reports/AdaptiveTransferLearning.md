#Distilling the Knowledge in a Neural Network　

## 軽量な計算リソースで、且つ高精度を目指し、ナレッジを余すところなく活用して教師モデルから生徒モデルに継承
https://arxiv.org/pdf/1503.02531.pdf
(2015/3)

* 教師モデルから生徒モデルにナレッジを転移。
 
  ・ナレッジ：教師モデルの正解ラベル＋不正解ラベルを含む全クラスの確率分布   

* 不正解確率分布を強調することを蒸留、温度パラメータで蒸留する度合いを決める 

  ・教師モデルのLogitsを0～1間の確率に変換（Softmax）の前に温度で割る  =>SoftTarget

* ２つのモデルをMNIST60000データのエラー数で比較実験 

  ・教師モデルAは67エラー、モデルBでは元々146エラーだったが、SoftTarget＋温度20で74エラーに

* ゴミ箱クラスを設けて実験

* 昆虫の話

## 今回のテーマ
→このKnowledge Distillation、次に紹介するTransfer Learningと類似している。　何が共通？

　両方に出てくる分布（Distribution）の違いを整理したい


---

#Domain Adaptive Transfer Learning with Specialist Models
https://arxiv.org/pdf/1811.07056.pdf
(2018/)


* 転移学習でどのようなソースドメインがターゲットドメインで精度を出せるか
　（ターゲットドメインが食べ物の分類なら、ソースドメインも食べ物であるべきか？）

* 同じソースとターゲットとの分布の差「重要性の重み」を精度に利用できるのでは



## Domain Adaptive Transfer Learning の手順

①ソースのデータセット=JFT（3億枚のデータ+18291クラス）で学習（事前学習）

②ターゲットのデータセットを、①のモデル（18291クラスそのまま）を使って学習

➂上記①の②の出力分布の差を、　重要性の重みとする。

　　②のラベルの確率　/（①におけるラベルの数÷①全体の数）=重要性の重み

④ターゲットのクラスを使って転移学習、➂重要性の重みを付与したうえでFine Tuning


## 実験結果

* Table 3．Inception v3：Adaptive Transfer が総じてTop1

* Table 4.　AmoebaNet：Adaptive Transfer が全体に高い

* Figure.2  ターゲットドメインごとに、重要性の重みをどれだけ加えたか（色が多いと多く加えたことに）　

* Figure.3  「重要性の重み」を正確に付与した場合とそうでない場合（ココわからん！）


## 分かったこと

* ターゲットの各クラスにおけるデータ数の分布が合致することが転移学習で重要　 

* Discriminative Factor（識別要因）が類似すると相性のいいドメインになる　 


---
# KD vs DATL (知識蒸留 vs 上記の転移学習)

* 目的
　　KD：精度に加えて処理速度を重視
　　DATL : 精度を重視（転移学習全般に処理速度の議論が少ない）

* 構造の違い
　　KD：教師モデルでの不正解を含む確率全体を生徒モデルに継承
　　DATL : ソースデータとターゲットデータをソースのモデルで比較、ターゲットに転移
　　
* 分布の意味の違い
　　KD：Softmaxによる出力スコアの分布　　
　　DATL : 各クラスのデータ数の分布　

## 個人的な課題
* 転移学習で予測時の処理速度向上を目指したい。