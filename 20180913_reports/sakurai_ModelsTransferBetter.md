#Do Better ImageNet Models Transfer Better ?

##(櫻井メモ)ImageNetで高精度であれば他のドメインでも精度が高いのは本当か？

===

Submitted on 2018/05
by Simon Kornblith, Jonathon Shlens, Quoc V. Le  (google brain)

論文リンク

https://arxiv.org/abs/1805.08974
（↑上記を開いて頂き、それをもとにご説明します）

---
## 動機

 Imagenetで学習したから他のドメインでも精度が高い、は本当か？
今なお、転移学習の体系的な研究成果はなされていない。

### 過去の研究では。。
* 分類したクラスの多さ（1000分類）が関係しているのでは？
* 1つのクラスにおけるデータの多さが関係しているのでは？
* 重み（特にCNNの後方の層における）が関係しているのでは？

　　　　　1層目の重みを固定にしても精度は落ちず、後方の層の重みを固定にすると精度が落ちる

###  　
---
## どうやって検証した？

  ImageNet以外の12のドメイン（Food101、Cifar10、Cifar100等）を、ImageNetで訓練した12のCNN（VGG、ResNet, Inception等）を使い、12×12のパターンで転移学習精度を比較した。


調査
1. ImageNetで利用されたCNNを固定の特徴抽出器として他のドメインに利用、結合層はそのドメインに沿ってロジスティック回帰　

* ResNetがどのドメインでも安定して高い精度を示す。

調査
２. CNNに加え、ImageNetで訓練済の重みを転移学習として利用。　

* ImageNetでの精度の高さが、他のドメインでも総じて再現。ImageNetの精度は他ドメインの精度の指標といえる。
* 調査1ののロジスティック回帰のパターン、またはランダムに一から学習するパターンと比較しても調査２は精度が高い

調査
３. 調査２の正解率と、そのドメインにおける過去最も高かった正解率と比較

* どのドメインでも、過去の数値より　調査２）転移学習のケースが優れる

調査
４. 調査1）ロジスティック回帰、調査２）転移学習の収束性をエポック数で比較

* どのドメインでも、調査２）が早く収束する。

調査
５. 少ないサンプルデータ数ににおける正解率のの比較

* どのドメインでも、調査２）が少ないデータ数で優れた精度を出す

---

## 議論はある？

* ImageNetで学習したモデル+重みを再利用すると、CNNの種類に関わらず精度が上がる。

* ImageNetの重み再利用は出発点。いかに特徴量を効率的に他ドメインに移植するかかが課題。

---

## 次に読むべき論文は？

引き続き、同様の論文を探して回ります。

